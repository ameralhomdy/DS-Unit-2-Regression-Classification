{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Second attempt assignment_regression_classification_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameralhomdy/DS-Unit-2-Regression-Classification/blob/master/module4/Second_attempt_assignment_regression_classification_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Regression & Classification, Module 4\n",
        "\n",
        "\n",
        "## Assignment\n",
        "\n",
        "- [ ] Watch Aaron's [video #1](https://www.youtube.com/watch?v=pREaWFli-5I) (12 minutes) & [video #2](https://www.youtube.com/watch?v=bDQgVt4hFgY) (9 minutes) to learn about the mathematics of Logistic Regression.\n",
        "- [ ] [Sign up for a Kaggle account](https://www.kaggle.com/), if you donâ€™t already have one. Go to our Kaggle InClass competition website. You will be given the URL in Slack. Go to the Rules page. Accept the rules of the competition.\n",
        "- [ ] Do train/validate/test split with the Tanzania Waterpumps data.\n",
        "- [ ] Begin with baselines for classification.\n",
        "- [ ] Use scikit-learn for logistic regression.\n",
        "- [ ] Get your validation accuracy score.\n",
        "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Clean the data. For ideas, refer to [The Quartz guide to bad data](https://github.com/Quartz/bad-data-guide),  a \"reference to problems seen in real-world data along with suggestions on how to resolve them.\" One of the issues is [\"Zeros replace missing values.\"](https://github.com/Quartz/bad-data-guide#zeros-replace-missing-values)\n",
        "- [ ] Make exploratory visualizations.\n",
        "- [ ] Do one-hot encoding. For example, you could try `quantity`, `basin`, `extraction_type_class`, and more. (But remember it may not work with high cardinality categoricals.)\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Get and plot your coefficients.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html).\n",
        "\n",
        "---\n",
        "\n",
        "## Data Dictionary \n",
        "\n",
        "### Features\n",
        "\n",
        "Your goal is to predict the operating condition of a waterpoint for each record in the dataset. You are provided the following set of information about the waterpoints:\n",
        "\n",
        "- `amount_tsh` : Total static head (amount water available to waterpoint)\n",
        "- `date_recorded` : The date the row was entered\n",
        "- `funder` : Who funded the well\n",
        "- `gps_height` : Altitude of the well\n",
        "- `installer` : Organization that installed the well\n",
        "- `longitude` : GPS coordinate\n",
        "- `latitude` : GPS coordinate\n",
        "- `wpt_name` : Name of the waterpoint if there is one\n",
        "- `num_private` :  \n",
        "- `basin` : Geographic water basin\n",
        "- `subvillage` : Geographic location\n",
        "- `region` : Geographic location\n",
        "- `region_code` : Geographic location (coded)\n",
        "- `district_code` : Geographic location (coded)\n",
        "- `lga` : Geographic location\n",
        "- `ward` : Geographic location\n",
        "- `population` : Population around the well\n",
        "- `public_meeting` : True/False\n",
        "- `recorded_by` : Group entering this row of data\n",
        "- `scheme_management` : Who operates the waterpoint\n",
        "- `scheme_name` : Who operates the waterpoint\n",
        "- `permit` : If the waterpoint is permitted\n",
        "- `construction_year` : Year the waterpoint was constructed\n",
        "- `extraction_type` : The kind of extraction the waterpoint uses\n",
        "- `extraction_type_group` : The kind of extraction the waterpoint uses\n",
        "- `extraction_type_class` : The kind of extraction the waterpoint uses\n",
        "- `management` : How the waterpoint is managed\n",
        "- `management_group` : How the waterpoint is managed\n",
        "- `payment` : What the water costs\n",
        "- `payment_type` : What the water costs\n",
        "- `water_quality` : The quality of the water\n",
        "- `quality_group` : The quality of the water\n",
        "- `quantity` : The quantity of water\n",
        "- `quantity_group` : The quantity of water\n",
        "- `source` : The source of the water\n",
        "- `source_type` : The source of the water\n",
        "- `source_class` : The source of the water\n",
        "- `waterpoint_type` : The kind of waterpoint\n",
        "- `waterpoint_type_group` : The kind of waterpoint\n",
        "\n",
        "### Labels\n",
        "\n",
        "There are three possible values:\n",
        "\n",
        "- `functional` : the waterpoint is operational and there are no repairs needed\n",
        "- `functional needs repair` : the waterpoint is operational, but needs repairs\n",
        "- `non functional` : the waterpoint is not operational\n",
        "\n",
        "--- \n",
        "\n",
        "## Generate a submission\n",
        "\n",
        "Your code to generate a submission file may look like this:\n",
        "\n",
        "```python\n",
        "# estimator is your model or pipeline, which you've fit on X_train\n",
        "\n",
        "# X_test is your pandas dataframe or numpy array, \n",
        "# with the same number of rows, in the same order, as test_features.csv, \n",
        "# and the same number of columns, in the same order, as X_train\n",
        "\n",
        "y_pred = estimator.predict(X_test)\n",
        "\n",
        "\n",
        "# Makes a dataframe with two columns, id and status_group, \n",
        "# and writes to a csv file, without the index\n",
        "\n",
        "sample_submission = pd.read_csv('sample_submission.csv')\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "submission.to_csv('your-submission-filename.csv', index=False)\n",
        "```\n",
        "\n",
        "If you're working locally, the csv file is saved in the same directory as your notebook.\n",
        "\n",
        "If you're using Google Colab, you can use this code to download your submission csv file.\n",
        "\n",
        "```python\n",
        "from google.colab import files\n",
        "files.download('your-submission-filename.csv')\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "# If you're in Colab...\n",
        "if in_colab:\n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Regression-Classification.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Install required python packages\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ipBYS77PUwNR",
        "colab": {}
      },
      "source": [
        "# Ignore this Numpy warning when using Plotly Express:\n",
        "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QJBD4ruICm1m",
        "colab": {}
      },
      "source": [
        "# Read the Tanzania Waterpumps data\n",
        "# train_features.csv : the training set features\n",
        "# train_labels.csv : the training set labels\n",
        "# test_features.csv : the test set features\n",
        "# sample_submission.csv : a sample submission file in the correct format\n",
        "    \n",
        "import pandas as pd\n",
        "\n",
        "train_features = pd.read_csv('../data/waterpumps/train_features.csv')\n",
        "train_labels = pd.read_csv('../data/waterpumps/train_labels.csv')\n",
        "test_features = pd.read_csv('../data/waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/waterpumps/sample_submission.csv')\n",
        "\n",
        "assert train_features.shape == (59400, 40)\n",
        "assert train_labels.shape == (59400, 2)\n",
        "assert test_features.shape == (14358, 40)\n",
        "assert sample_submission.shape == (14358, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Amxyx3xphbb",
        "colab": {}
      },
      "source": [
        "# import block\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import f_regression, SelectKBest\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
        "import category_encoders as ce "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pPVK0w_CuPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3691f50-458f-4c28-9e55-797784a82df0"
      },
      "source": [
        "# Train-validation split\n",
        "\n",
        "X_train = train_features.copy()\n",
        "y_train = train_labels['status_group'].copy()\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, train_size = 0.80, test_size = 0.20,\n",
        "    stratify = y_train, random_state = 42)\n",
        "\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47520, 40), (11880, 40), (47520,), (11880,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shchFdpqDhUc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "28de7dcb-a648-40f9-95f0-b2bf0a4a5c2c"
      },
      "source": [
        "for col in X_train.select_dtypes('object').columns:\n",
        "    print(col)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "date_recorded\n",
            "funder\n",
            "installer\n",
            "wpt_name\n",
            "basin\n",
            "subvillage\n",
            "region\n",
            "lga\n",
            "ward\n",
            "public_meeting\n",
            "recorded_by\n",
            "scheme_management\n",
            "scheme_name\n",
            "permit\n",
            "extraction_type\n",
            "extraction_type_group\n",
            "extraction_type_class\n",
            "management\n",
            "management_group\n",
            "payment\n",
            "payment_type\n",
            "water_quality\n",
            "quality_group\n",
            "quantity\n",
            "quantity_group\n",
            "source\n",
            "source_type\n",
            "source_class\n",
            "waterpoint_type\n",
            "waterpoint_type_group\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEECG291DlaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "fee10942-0857-4b46-e9c4-1897049aba4b"
      },
      "source": [
        "# Fill the frame with the mode for object feature\n",
        "for column in X_train.select_dtypes('object').columns:\n",
        "    X_train[column].fillna(X_train[column].mode()[0], inplace=True)\n",
        "    X_val[column].fillna(X_train[column].mode()[0], inplace=True)\n",
        "    test_features[column].fillna(X_train[column].mode()[0], inplace=True)\n",
        "    \n",
        "# Fill the frame with the mean for numeric features\n",
        "for column in X_train.select_dtypes('number').columns:\n",
        "    X_train[column].fillna(X_train[column].mean(), inplace=True)\n",
        "    X_val[column].fillna(X_train[column].mean(), inplace=True)\n",
        "    test_features[column].fillna(X_train[column].mean(), inplace=True)\n",
        "    \n",
        "X_val.isna().sum()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                       0\n",
              "amount_tsh               0\n",
              "date_recorded            0\n",
              "funder                   0\n",
              "gps_height               0\n",
              "installer                0\n",
              "longitude                0\n",
              "latitude                 0\n",
              "wpt_name                 0\n",
              "num_private              0\n",
              "basin                    0\n",
              "subvillage               0\n",
              "region                   0\n",
              "region_code              0\n",
              "district_code            0\n",
              "lga                      0\n",
              "ward                     0\n",
              "population               0\n",
              "public_meeting           0\n",
              "recorded_by              0\n",
              "scheme_management        0\n",
              "scheme_name              0\n",
              "permit                   0\n",
              "construction_year        0\n",
              "extraction_type          0\n",
              "extraction_type_group    0\n",
              "extraction_type_class    0\n",
              "management               0\n",
              "management_group         0\n",
              "payment                  0\n",
              "payment_type             0\n",
              "water_quality            0\n",
              "quality_group            0\n",
              "quantity                 0\n",
              "quantity_group           0\n",
              "source                   0\n",
              "source_type              0\n",
              "source_class             0\n",
              "waterpoint_type          0\n",
              "waterpoint_type_group    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ4UeG1nGUsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mapping the ys to integers for the encoder\n",
        "mapdict = {\n",
        "    'functional': 1,\n",
        "    'non functional': -1,\n",
        "    'functional needs repair': 0\n",
        "}\n",
        "y_train = y_train.map(mapdict)\n",
        "y_val = y_val.map(mapdict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WesN1Y01DpEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c35e614c-cc1a-44b3-a25c-cab2b1dbcf8b"
      },
      "source": [
        "# Using category encoder to establish feature rank\n",
        "\n",
        "categoryfeatures = X_train.select_dtypes(include = 'object').columns\n",
        "\n",
        "encoder = ce.cat_boost.CatBoostEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
        "X_val_scaled = scaler.transform(X_val_encoded)\n",
        "\n",
        "model = LogisticRegressionCV()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print('Validation Accuracy', model.score(X_val_scaled, y_val))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7552188552188552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYLGa0u9Jf5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transforming the test data\n",
        "X_test_subset = test_features\n",
        "X_test_encoded = encoder.transform(X_test_subset)\n",
        "X_test_scaled = scaler.transform(X_test_encoded)\n",
        "assert all(X_test_encoded.columns == X_train_encoded.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPH8XxgIKFfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicting the test data\n",
        "y_test_pred = model.predict(X_test_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hXTsIzKH-wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unmapping the prediction\n",
        "y_test_pred = pd.Series(y_test_pred)\n",
        "unmapdict = {value: key for key, value in mapdict.items()}\n",
        "y_test_pred = y_test_pred.map(unmapdict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMdP_hctJDyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Formatting submission\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_test_pred\n",
        "submission.to_csv('submission-Amer2.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}